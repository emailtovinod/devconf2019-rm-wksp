:sectnums:
:hardbreaks:
:scrollbar:
:data-uri:
:toc2:
:showdetailed:
:number:
:toc-title: Workshop Tasks
:imagesdir: ./images

== POD Resource Management Workshop

=== Demo App deployment

As the first task you need to create/use a project (namespace) in the OpenShift cluster to deploy the demo app and configure resources.

. Export the provided `GUID` to the terminal session of the `client VM`.
+
[%nowrap]
----
export GUID=<Please type the GUID provided by the workshop facilitator>
----
[TIP]
The workshop facilitator will provide the GUID.

. Log into the OpenShift cluster using the credentials and URL provided by the workshop facilitator.
+
[%nowrap]
----
oc login -u <USER NAME> <URL>
----
+
[TIP]
The workshop facilitator will provide the `URL` and `USER NAME.` Typically the `USER NAME` and the `GUID` will be the same for the workshop. The `PASSWORD` also will be provided by the facilitator.
 
. Switch to the project(namespace) assigned by the workshop facilitator.
+
[%nowrap]
----
oc project $GUID-rm-demo
----
+

. Clone manifest for the `demo` app.
+
[%nowrap]
----
git clone https://github.com/emailtovinod/rm-demo.git
----
+
. Create the `demo` app using the manifest file.
+
[%nowrap]
----
oc create -f rm-demo/rm-lab-dc.yaml 
----
+
.Sample Output
----
deploymentconfig.apps.openshift.io/rm-demo-app created
----

. Please verify that that the `demo` app POD is created 
+
[%nowrap]
----
oc get pods
----
+

.Sample Output (NAME and AGE parameters may vary in your output)
----
NAME                  READY     STATUS    RESTARTS   AGE
rm-demo-app-3-bswfr   1/1       Running   0          57m
----
. Expose the `deploymentconfig` to create `service` for the `demo` app
+
[%nowrap]
----
oc expose dc/rm-demo-app
----
+
.Sample Output 
----
service/rm-demo-app exposed
----

. Expose the `service` to create `route` (ingress URL) for the demo app.
+
[%nowrap]
----
oc expose svc/rm-demo-app
----
+
.Sample Output
----
route.route.openshift.io/rm-demo-app exposed
----
. List the route of the demo app
+
[%nowrap]
----
oc get route
----
+
.Sample Output (HOST/PORT parameter may vary in your Output)
+
----
NAME          HOST/PORT                                           PATH      SERVICES      PORT      TERMINATION   WILDCARD
rm-demo-app   rm-demo-app-test3.apps.cdf7.openshift.opentlc.com             rm-demo-app   port-1                  None

----
+


=== POD Resource and QoS testing

Let's  check the Resource Settings and Quality of Service (QoS) of the `demo` application `rm-demo` 

[NOTE]
The route you created will provide an external `http url` to access the application. To save some typing, you may execute the below command to see the actual url for the demo application.

. Please execute the command
+
[%nowrap]
----
echo `oc get route -o jsonpath={.items[0].spec.host}`/resource.php
----
+

.Sample Output (The URL may vary in your output)
+
[%nowrap]
----
rm-demo-app-user51-rm-demo.apps.cdf7.openshift.opentlc.com/resource.php
----
+

. Now you need to copy the URL and paste in your workstation browser address bar or in plain and simple, access the URL using a browser ( It is recommended to use chrome/firefox)

[NOTE]
Please note the resource configuration (CPU and MEMORY) of the application container displaying in the browser. Since we did not configure resource `request` and `limit` for the Container,the resources of its host machine (compute node) is set as its soft `resource limit`. Also note that there is no `resource request` ( CPU and memory reservation) during the POD schedule.

. Check the Quality of Service (QoS) of the application POD.
+
[%nowrap]
----
oc describe po | grep -i qos
----
+

.Sample Output

+
[%nowrap]
----
QoS Class:       BestEffort
----
+

[TIP]
Since we have only one POD in the project(namespace), the command will show the QoS of the pod. If you have multiple PODs in the project, need to specify the pod name to describe the specific POD.

[NOTE]
POD having the `BestEffort QoS Class` are treated with the lowest priority. Processes in these containers are first to be killed if the system runs out of memory.



=== Set the Resource Configuration

In this part of the lab you set the resource configuration for the demo application container `rm-demo` and verify the change in the `QOS Class` of the POD.

. Configure the resource request for the `rm-demo` application container.

+
[%nowrap]
----
oc set resources dc/rm-demo-app --requests cpu=250m,memory=256Mi
----
+

[TIP]

Wait for a few seconds (`~30-40sec.`) to create a new container before proceeding.ConfigChange trigger in OpenShift DeploymentConfig results in a new deployment whenever changes are detected to the replication controller template of the deployment configuration. In our scenario, the new POD will have CPU and MEMORY resource `request` settings.
 
. Now refresh the browser which displays the resource settings [ Accessing the Application URL ] and observes the changes in the `resource request`.

. Check the Quality of Service (QoS) of the application POD.

+
[%nowrap]
----
oc describe po | grep -i qos
----
+

.Sample Output
+
[%nowrap]
----
QoS Class:       Burstable
----
+

NOTE: Please note that the POD QoS changed to Burstable. Now the scheduler schedules the POD to a node which meets its resource request. Still, the resource limit shows the available CPU and MEMORY resource of its node. When `resource limits` are not specified, they default to the node capacity. The PODs having Burstable QoS Class get second best priority in the cluster.containers under system memory pressure are more likely to be killed once they exceed their requests and no other BestEffort containers exist.


. Go ahead and set the resource limits for the POD, which is slightly higher than the resource request.

+
[%nowrap]
----
oc set resources dc/rm-demo-app --requests cpu=250m,memory=256Mi --limits cpu=512m,memory=512Mi
----
+

[TIP]

Wait for a few seconds (`~30-40sec.`) to create a new container before proceeding.ConfigChange trigger in OpenShift DeploymentConfig results in a new deployment whenever changes are detected to the replication controller template of the deployment configuration. In our scenario, the new  POD has CPU and MEMORY resource `request` and `limits` settings.

. Now refresh the browser which displays the resource settings [ Accessing the Application URL ]  and observes the changes in the resource request.
 
. Check the Quality of Service (QoS) of the application POD.

+ 
[%nowrap]
----
oc describe po | grep -i qos
----
+

.Sample Output
+
[%nowrap]
----
QoS Class:       Burstable
----
+

NOTE: Even though the QoS remains the same - Burstable - as in the case of `request` only setting, here we set the `limit` for the run time resource consumption of the POD. 

. As the next task, set the value of resource `limit` as that of resource `request`.
+
[%nowrap]
----
oc set resources dc/rm-demo-app --requests cpu=250m,memory=256Mi --limits cpu=250m,memory=256Mi
----
+

[TIP]
Wait for a few seconds (`~30-40sec.`) to create a new container before proceeding.ConfigChange trigger in OpenShift DeploymentConfig results in a new deployment whenever changes are detected to the replication controller template of the deployment configuration. In our current scenario, the new POD has CPU and MEMORY resource `request` and the same values set for resource `limits`  too.

. Please refresh the browser which displays the resource settings [ Accessing the Application URL ]  and observes the changes in the resource request.

. Check the Quality of Service (QoS) of the application POD.

+
[%nowrap]
----
oc describe po | grep -i qos
----
+

.Sample Output
+
[%nowrap]
----
QoS Class:       Guaranteed
----
+

[NOTE]
Note that the QoS of the POD changed from `Burstable` to `Guaranteed`. Pods with `Guaranteed QoS Class` are considered top-priority and are guaranteed not to be killed until they exceed their limits.


=== LimitRange Configuration
 
It is the time to configure and test the `limitrange` admission control. To verify the `limitrange` enforcement, we need to `rollback` the application deploymentconfiguration to the first revision, the one without any resource settings.

[NOTE]
OpenShift `deploymentconfig` rollback function  revert an application back to a previous revision and is very handy to `undo` changes in the deployment.

. Execute the following command to rollback to the firt revision without the resources configuration.

+
[%nowrap]
----
oc rollout undo dc/rm-demo-app --to-revision=1
----
+

. Please refresh the browser which displays the resource settings and verify the changes.

. Create a `limitrange` object in the `namespace` using the provided manifest.


+
[%nowrap]
----
oc create -f rm-demo/limit-mem-cpu-per-container.yaml
----
+

. List the `limitrange` object in the namespace.

+
[%nowrap]
----
oc get limitranges
----
+

.Sample Output
----
NAME                          CREATED AT
limit-mem-cpu-per-container   2019-07-28T06:59:09Z
----

. Rollout a new `replication controller` by executing the command.

+
[%nowrap]
----
oc rollout latest dc/rm-demo-app
----
+

_You may wait for a minute to complete the creation of the new Pod!!!!_

. Hey, lets refresh the browser and observe the changes in the Pod resources.


**Congratulations!!!You Did it...Now you become a Pod Resource Management Ninja!!!!**




 
